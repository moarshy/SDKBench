{
  "score": 0.0,
  "tests_passed": 2,
  "tests_failed": 1,
  "tests_total": 3,
  "tests_skipped": 0,
  "duration": 8.780227661132812,
  "error": "1 tests failed",
  "failed_tests": [
    "test_pipeline_end_to_end"
  ],
  "failure_details": [
    {
      "test_name": "test_pipeline_end_to_end",
      "file_path": "tests/test_pipeline.py",
      "line_number": 38,
      "error_message": "assert False",
      "stack_trace": "tests/test_pipeline.py:38: in test_pipeline_end_to_end\n    assert isinstance(response, str)\nE   assert False\nE    +  where False = isinstance({'query': 'test query', 'response': \"Based on the retrieved context, here's the answer to your query:\\n\\nQuery: test query\\n\\nRelevant Context:\\n[Document 1] Test content for pipeline\\n\\nAnswer: Based on the above documents, test query can be understood through the following key points:\\n- The retrieved documents provide relevant information about the topic\\n- Multiple perspectives and details are available in the context\\n- This information helps form a comprehensive understanding\\n\\n(Note: This is a mock response. In production, an LLM would generate a proper answer.)\\n\", 'retrieved_documents': [{'id': 0, 'score': 1.5338044166564941, 'text': 'Test content for pipeline'}]}, str)\n----------------------------- Captured stdout call -----------------------------\nCreated table 'documents' with 1 documents\n\n============================================================\nRunning HYDE-enhanced RAG pipeline\nQuery: test query\n============================================================\n\nRetrieved 1 documents:\n\n1. [Score: 1.5338] Test content for pipeline...\n\nGenerating response..."
    }
  ],
  "raw_output": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.0, pytest-9.0.1, pluggy-1.6.0 -- /Users/arshath/miniforge3/bin/python\ncachedir: .pytest_cache\nrootdir: /private/var/folders/wx/bj4n9pyj10n74txq4mpt0j9h0000gn/T/fcorr_1x81r8g6\nplugins: anyio-4.7.0\ncollecting ... collected 3 items\n\ntests/test_pipeline.py::test_document_ingestion PASSED                   [ 33%]\ntests/test_pipeline.py::test_search_returns_results PASSED               [ 66%]\ntests/test_pipeline.py::test_pipeline_end_to_end FAILED                  [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_pipeline_end_to_end ___________________________\ntests/test_pipeline.py:38: in test_pipeline_end_to_end\n    assert isinstance(response, str)\nE   assert False\nE    +  where False = isinstance({'query': 'test query', 'response': \"Based on the retrieved context, here's the answer to your query:\\n\\nQuery: test query\\n\\nRelevant Context:\\n[Document 1] Test content for pipeline\\n\\nAnswer: Based on the above documents, test query can be understood through the following key points:\\n- The retrieved documents provide relevant information about the topic\\n- Multiple perspectives and details are available in the context\\n- This information helps form a comprehensive understanding\\n\\n(Note: This is a mock response. In production, an LLM would generate a proper answer.)\\n\", 'retrieved_documents': [{'id': 0, 'score': 1.5338044166564941, 'text': 'Test content for pipeline'}]}, str)\n----------------------------- Captured stdout call -----------------------------\nCreated table 'documents' with 1 documents\n\n============================================================\nRunning HYDE-enhanced RAG pipeline\nQuery: test query\n============================================================\n\nRetrieved 1 documents:\n\n1. [Score: 1.5338] Test content for pipeline...\n\nGenerating response...\n\n=========================== short test summary info ============================\nFAILED tests/test_pipeline.py::test_pipeline_end_to_end - assert False\n========================= 1 failed, 2 passed in 7.33s ==========================\n"
}